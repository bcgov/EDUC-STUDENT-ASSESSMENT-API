$=$
#logging Properties
logging.level.org.springframework.security=${SPRING_SECURITY_LOG_LEVEL}
logging.level.org.springframework.web=${SPRING_WEB_LOG_LEVEL}
logging.level.ca.bc.gov.educ.assessment=${APP_LOG_LEVEL}
logging.level.org.springframework.boot.autoconfigure.logging=${SPRING_BOOT_AUTOCONFIG_LOG_LEVEL}
spring.mvc.log-request-details=${SPRING_SHOW_REQUEST_DETAILS}

#DB Properties
spring.datasource.url=${JDBC_URL}
spring.datasource.username=${DB_USERNAME}
spring.datasource.password=${DB_PASSWORD}
spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.hibernate.ddl-auto=none
timing.initialDelay=1
spring.jackson.deserialization.fail-on-unknown-properties=true
spring.security.oauth2.resourceserver.jwt.issuer-uri=${TOKEN_ISSUER_URL}
spring.security.oauth2.resourceserver.jwt.jwk-set-uri=${TOKEN_ISSUER_URL}/protocol/openid-connect/certs
management.endpoint.metrics.enabled=true
management.endpoints.web.exposure.include=*
management.endpoint.prometheus.enabled=true
management.prometheus.metrics.export.enabled=true
spring.jpa.properties.hibernate.generate_statistics=false
spring.jpa.properties.hibernate.jdbc.batch_size=999
spring.jpa.properties.hibernate.order_inserts=true
spring.datasource.hikari.data-source-properties.reWriteBatchedInserts=true
spring.datasource.hikari.max-lifetime=120000
spring.jmx.enabled=false
spring.flyway.baseline-on-migrate=true
spring.flyway.table=FLYWAY_SCHEMA_HISTORY
spring.flyway.baseline-version=0
spring.flyway.enabled=true
logging.file.name=/logs/app.log
logging.logback.rollingpolicy.max-file-size=5MB
logging.logback.rollingpolicy.clean-history-on-start=true
logging.logback.rollingpolicy.max-history=1
logging.pattern.file={"time_stamp":"%d{yyyy-MM-dd HH:mm:ss.SSS}","level":"%3p" ,"thread":"%t" ,"class":"%logger{36}","msg":"%replace(%msg){'[\n\r\"]',''}", "exception":"%replace(%rEx{10}){'[\n\r\"]',''}","http_event":%X{httpEvent:-""},"message_event":%X{messageEvent:-""}, "saga_retry":%X{sagaRetry:-""}}%nopex%n
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss.SSS} | [%5p] | [%t] | [%logger{36}] | [%replace(%msg){'[\n\r\"]',''} %X{httpEvent} %X{messageEvent}] | %replace(%rEx{10}){'[\n\r\"]',''}%nopex%n

#This is required to map long raw, please see below links, even if hibernate documentation mentions {hibernate.dialect.oracle.prefer_longvarbinary}
# this as the property name, it is not correct.
#https://hibernate.atlassian.net/browse/HHH-10345
#https://in.relation.to/2016/02/17/hibernate-orm-508-final-release/
#spring.jpa.properties.hibernate.dialect.oracle.prefer_long_raw=true
#Print the queries
spring.jpa.show-sql=${SPRING_JPA_SHOW_SQL}

spring.jpa.open-in-view=false
#Client details to get token to make api calls.
client.id=${CLIENT_ID}
client.secret=${CLIENT_SECRET}
url.token=${TOKEN_URL}

nats.server=${NATS_URL}
nats.maxReconnect=${NATS_MAX_RECONNECT}
nats.connectionName=ASSESSMENT-API
initialization.background.enabled=true

threads.min.subscriber=${THREADS_MIN_SUBSCRIBER}
threads.max.subscriber=${THREADS_MAX_SUBSCRIBER}

url.api.institute=${INSTITUTE_API_URL}
url.api.sdc=${SDC_API_URL}
schedule.jobs.load.school.cron=0 0 0/12 * * *

spring.datasource.hikari.maximum-pool-size=${MAXIMUM_DB_POOL_SIZE}
spring.datasource.hikari.minimum-idle=${MINIMUM_IDLE_DB_POOL_SIZE}

purge.records.saga.after.days=${PURGE_RECORDS_SAGA_AFTER_DAYS}
scheduled.jobs.purge.old.saga.records.cron=${SCHEDULED_JOBS_PURGE_OLD_SAGA_RECORDS_CRON}

server.max-http-request-header-size=2MB

number.students.process.saga=${NUMBER_OF_STUDENTS_TO_PROCESS_SAGA}
scheduled.jobs.publish.loaded.assessment.students.cron=${SCHEDULED_JOBS_PUBLISH_LOADED_ASSESSMENT_STUDENTS_CRON}
scheduled.jobs.publish.loaded.assessment.students.cron.lockAtLeastFor=${SCHEDULED_JOBS_PUBLISH_LOADED_ASSESSMENT_STUDENTS_CRON_LOCK_AT_LEAST_FOR}
scheduled.jobs.publish.loaded.assessment.students.cron.lockAtMostFor=${SCHEDULED_JOBS_PUBLISH_LOADED_ASSESSMENT_STUDENTS_CRON_LOCK_AT_MOST_FOR}

scheduled.jobs.setup.sessions.cron=${SCHEDULED_JOBS_SETUP_SESSIONS_CRON}
scheduled.jobs.setup.sessions.cron.lockAtLeastFor=${SCHEDULED_JOBS_SETUP_SESSIONS_CRON_LOCK_AT_LEAST_FOR}
scheduled.jobs.setup.sessions.cron.lockAtMostFor=${SCHEDULED_JOBS_SETUP_SESSIONS_CRON_LOCK_AT_MOST_FOR}

scheduled.jobs.extract.uncompleted.sagas.cron=${SCHEDULED_JOBS_EXTRACT_UNCOMPLETED_SAGAS_CRON}
scheduled.jobs.extract.uncompleted.sagas.cron.lockAtLeastFor=${SCHEDULED_JOBS_EXTRACT_UNCOMPLETED_SAGAS_CRON_LOCK_AT_LEAST_FOR}
scheduled.jobs.extract.uncompleted.sagas.cron.lockAtMostFor=${SCHEDULED_JOBS_EXTRACT_UNCOMPLETED_SAGAS_CRON_LOCK_AT_MOST_FOR}

scheduled.jobs.purge.completed.results.cron=${SCHEDULED_JOBS_PURGE_COMPLETED_RESULTS_FROM_STAGING_CRON}
scheduled.jobs.purge.completed.results.cron.lockAtLeastFor=${SCHEDULED_JOBS_PURGE_COMPLETED_RESULTS_FROM_STAGING_CRON_LOCK_AT_LEAST_FOR}
scheduled.jobs.purge.completed.results.cron.lockAtMostFor=${SCHEDULED_JOBS_PURGE_COMPLETED_RESULTS_FROM_STAGING_CRON_LOCK_AT_MOST_FOR}

email.subject.myed.approval.notification=${EMAIL_SUBJECT_MYED_APPROVAL_NOTIFICATION}
email.myed.approval.from=${EMAIL_MYED_APPROVAL_NOTIFICATION_FROM}
email.myed.approval.to=${EMAIL_MYED_APPROVAL_NOTIFICATION_TO}
email.template.myed.approval.notification=${EMAIL_TEMPLATE_MYED_APPROVAL_NOTIFICATION}

ches.client.id=${CHES_CLIENT_ID}
ches.client.secret=${CHES_CLIENT_SECRET}
ches.token.url=${CHES_TOKEN_URL}
ches.endpoint.url=${CHES_ENDPOINT_URL}

s3.access.key.id=${S3_ACCESS_KEY_ID}
s3.access.secret.key=${S3_ACCESS_SECRET_KEY}
s3.bucket.name=${S3_BUCKET_NAME}
s3.endpoint.url=${S3_ENDPOINT_URL}
coms.endpoint.url=${COMS_ENDPOINT_URL}
